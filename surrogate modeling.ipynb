{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421411a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ce5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = pd.read_excel('data/results_large.xlsx', engine = \"openpyxl\")\n",
    "file_list = list(cd['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71ec4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "image1 = {}\n",
    "image2 = {}\n",
    "i = 0\n",
    "\n",
    "A = {}\n",
    "L = {}\n",
    "l = {}\n",
    "w = {}\n",
    "h = {}\n",
    "for item in file_list:\n",
    "    path1 = os.path.join('data/depth', item+'.obj.png')\n",
    "    path2 = os.path.join('data/normal', item+'.obj.png')\n",
    "#     path = os.path.join('data/perspective', item+'.obj.png')\n",
    "#     path = os.path.join('data/', item+\".obj\", 'top.png')\n",
    "#     path = os.path.join('data/', item+\".obj\", 'bottom.png')\n",
    "#     path = os.path.join('data/', item+\".obj\", 'left.png')\n",
    "#     path = os.path.join('data/', item+\".obj\", 'right.png')\n",
    "#     path = os.path.join('data/', item+\".obj\", 'front.png')\n",
    "#     path = os.path.join('data/', item+\".obj\", 'back.png')\n",
    "    if exists(path1):\n",
    "        i += 1\n",
    "        img = cv2.imread(path1)\n",
    "        img = cv2.resize(img, (384,384), interpolation = cv2.INTER_AREA)\n",
    "        image1[item] = img\n",
    "        img = cv2.imread(path2)\n",
    "        img = cv2.resize(img, (384,384), interpolation = cv2.INTER_AREA)\n",
    "        image2[item] = img\n",
    "    else:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a05a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = cd[cd['set'] == 'train'] \n",
    "val_df = cd[cd['set'] == 'val'] \n",
    "test_df = cd[cd['set'] == 'test'] \n",
    "\n",
    "train_graph1 = [image1[i] for i in train_df['file']]\n",
    "val_graph1 = [image1[i] for i in val_df['file']]\n",
    "test_graph1 = [image1[i] for i in test_df['file']]\n",
    "all_graph1 = [image1[i] for i in cd['file']]\n",
    "\n",
    "train_graph2 = [image2[i] for i in train_df['file']]\n",
    "val_graph2 = [image2[i] for i in val_df['file']]\n",
    "test_graph2 = [image2[i] for i in test_df['file']]\n",
    "all_graph2 = [image2[i] for i in cd['file']]\n",
    "\n",
    "x_train1 = np.array(train_graph1)/255\n",
    "x_val1 = np.array(val_graph1)/255\n",
    "x_test1 = np.array(test_graph1)/255\n",
    "x_all1 = np.array(all_graph1)/255\n",
    "\n",
    "x_train2 = np.array(train_graph2)/255\n",
    "x_val2 = np.array(val_graph2)/255\n",
    "x_test2 = np.array(test_graph2)/255\n",
    "x_all2 = np.array(all_graph2)/255\n",
    "\n",
    "train_cost = np.array(train_df['Cd'])\n",
    "val_cost = np.array(val_df['Cd'])\n",
    "test_cost = np.array(test_df['Cd'])\n",
    "all_cost = np.array(cd['Cd'])\n",
    "\n",
    "image_shape = train_graph1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ac03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = cd[cd['set'] == 'test'] \n",
    "test_graph1 = [image1[i] for i in test_df['file']]\n",
    "test_graph2 = [image2[i] for i in test_df['file']]\n",
    "x_test1 = np.array(test_graph1)/255\n",
    "x_test2 = np.array(test_graph2)/255\n",
    "test_cost = np.array(test_df['Cd'])\n",
    "\n",
    "x_test1 = torch.tensor(x_test1,dtype=torch.float)\n",
    "x_test1 = torch.transpose(x_test1, 1, 3)\n",
    "x_test2 = torch.tensor(x_test2,dtype=torch.float)\n",
    "x_test2 = torch.transpose(x_test2, 1, 3)\n",
    "test_cost = torch.tensor(test_cost,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa5479d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 24\n",
    "\n",
    "x_train1 = torch.tensor(x_train1,dtype=torch.float)\n",
    "x_train1 = torch.transpose(x_train1, 1, 3)\n",
    "x_train2 = torch.tensor(x_train2,dtype=torch.float)\n",
    "x_train2 = torch.transpose(x_train2, 1, 3)\n",
    "train_cost = torch.tensor(train_cost,dtype=torch.float)\n",
    "\n",
    "x_val1 = torch.tensor(x_val1,dtype=torch.float)\n",
    "x_val1 = torch.transpose(x_val1, 1, 3)\n",
    "x_val2 = torch.tensor(x_val2,dtype=torch.float)\n",
    "x_val2 = torch.transpose(x_val2, 1, 3)\n",
    "val_cost = torch.tensor(val_cost,dtype=torch.float)\n",
    "\n",
    "x_test1 = torch.tensor(x_test1,dtype=torch.float)\n",
    "x_test1 = torch.transpose(x_test1, 1, 3)\n",
    "x_test2 = torch.tensor(x_test2,dtype=torch.float)\n",
    "x_test2 = torch.transpose(x_test2, 1, 3)\n",
    "test_cost = torch.tensor(test_cost,dtype=torch.float)\n",
    "\n",
    "x_all1 = torch.tensor(x_all1,dtype=torch.float)\n",
    "x_all1 = torch.transpose(x_all1, 1, 3)\n",
    "x_all2 = torch.tensor(x_all2,dtype=torch.float)\n",
    "x_all2 = torch.transpose(x_all2, 1, 3)\n",
    "all_cost = torch.tensor(all_cost,dtype=torch.float)\n",
    "\n",
    "train_data = TensorDataset(x_train1, x_train2, train_cost)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(x_val1, x_val2, val_cost)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(x_test1, x_test2, test_cost)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)\n",
    "\n",
    "all_data = TensorDataset(x_all1, x_all2, all_cost)\n",
    "all_sampler = SequentialSampler(all_data)\n",
    "all_dataloader = DataLoader(all_data, sampler = all_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce49194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from attention import ScaledDotProductAttention\n",
    "pretrained01 = models.resnext101_32x8d(pretrained=True)\n",
    "pretrained = pretrained01.to(device)\n",
    "pretrained = nn.Sequential(*list(pretrained.children())[:-2])\n",
    "\n",
    "pretrained02 = models.resnext101_32x8d(pretrained=True)\n",
    "pretrained1 = pretrained02.to(device)\n",
    "pretrained1 = nn.Sequential(*list(pretrained1.children())[:-2])\n",
    "\n",
    "# from torchsummary import summary\n",
    "# summary(model2, (3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a6c6d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = 128\n",
    "drop1 = 0.0\n",
    "drop2 = 0.0\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "    def forward(self, x):\n",
    "        return x.reshape([x.shape[0],x.shape[1],x.shape[2]*x.shape[3]])\n",
    "class NORMAL(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained):\n",
    "      \n",
    "        super(NORMAL, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        self.attn = ScaledDotProductAttention(dim=fc)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.reshape = Reshape()\n",
    "        self.dropout1 = nn.Dropout(drop1)\n",
    "        self.dropout2 = nn.Dropout(drop2)\n",
    "        self.relu =  nn.ReLU()\n",
    "        self.fc = fc\n",
    "        self.fc1 = nn.Linear(2048,self.fc)\n",
    "        self.fc2 = nn.Linear(2048,self.fc)\n",
    "        self.fc3 = nn.Linear(2048,self.fc)\n",
    "        self.fc4 = nn.Linear(144*self.fc,self.fc)\n",
    "        self.fc5 = nn.Linear(self.fc,1)\n",
    "\n",
    "    def forward(self, x_train):\n",
    "        x = self.pretrained(x_train)\n",
    "        y = self.reshape(x)\n",
    "        y = torch.permute(y, (0, 2, 1))\n",
    "        key = self.fc2(y)\n",
    "        key = self.relu(key)\n",
    "        query = self.fc2(y)\n",
    "        query = self.relu(query)\n",
    "        value = self.fc3(y)\n",
    "        value = self.relu(value)\n",
    "        context, attn = self.attn(query, key, value)\n",
    "        context = self.flat(context)\n",
    "        context = self.dropout1(context)\n",
    "        context = self.fc4(context)\n",
    "        context = self.relu(context)\n",
    "        x = self.fc5(context)\n",
    "        x = self.relu(x)\n",
    "        return x, context, key, query, value\n",
    "    \n",
    "normal = NORMAL(pretrained)\n",
    "path1 = 'trained models/attn2_rec_normal_resnext_8e-05_128_0.96_large_3.pt'\n",
    "normal.load_state_dict(torch.load(path1))\n",
    "# for param in normal.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f86115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEPTH(nn.Module):\n",
    "    def __init__(self, pretrained1):    \n",
    "        super(DEPTH, self).__init__()\n",
    "        self.pretrained = pretrained1\n",
    "        self.attn = ScaledDotProductAttention(dim=fc)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.reshape = Reshape()\n",
    "        self.relu =  nn.ReLU()\n",
    "        self.fc = fc\n",
    "        self.fc1 = nn.Linear(2048,self.fc)\n",
    "        self.fc2 = nn.Linear(2048,self.fc)\n",
    "        self.fc3 = nn.Linear(144*self.fc,self.fc)\n",
    "        self.out = nn.Linear(self.fc,1)\n",
    "    def forward(self, x_train):\n",
    "        x = self.pretrained(x_train)\n",
    "        y = self.reshape(x)\n",
    "        y = torch.permute(y, (0, 2, 1))\n",
    "        key = self.fc1(y)\n",
    "        key = self.relu(key)\n",
    "        query = self.fc1(y)\n",
    "        query = self.relu(query)\n",
    "        value = self.fc2(y)\n",
    "        value = self.relu(value)\n",
    "        context, attn = self.attn(query, key, value)\n",
    "        context = self.flat(context)\n",
    "        context = self.fc3(context)\n",
    "        context = self.relu(context)\n",
    "        x = self.out(context)\n",
    "        x = self.relu(x)\n",
    "        return x, context, key, query, value\n",
    "    \n",
    "depth = DEPTH(pretrained1)\n",
    "path2 = 'trained models/attn2_rec_depth_resnext_3e-05_128_0.96_large_3.pt'\n",
    "depth.load_state_dict(torch.load(path2))\n",
    "for param in depth.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bbbcc",
   "metadata": {},
   "source": [
    "# simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9635ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, normal, depth):\n",
    "      \n",
    "#         super(CNN, self).__init__()\n",
    "#         self.model1 = normal\n",
    "#         self.model2 = depth\n",
    "#         self.out = nn.Linear(2,1)\n",
    "#         with torch.no_grad():\n",
    "#             self.out.weight = nn.Parameter(torch.tensor(reg.coef_, dtype=torch.float).reshape(1,2))\n",
    "# #             self.out.weight = nn.Parameter(torch.tensor([1,0], dtype=torch.float).reshape(1,2))\n",
    "#             self.out.bias = nn.Parameter(torch.tensor(np.array([bias]), dtype=torch.float))\n",
    "#         self.relu = nn.ReLU()\n",
    "#     def forward(self, x_train1, x_train2):\n",
    "#         x1,context1,key1,query1,value1 = self.model1(x_train1)\n",
    "#         x2,context2,key2,query2,value2 = self.model2(x_train2)  \n",
    "#         z = torch.cat([x, y],dim=1)\n",
    "#         z = self.out(z)\n",
    "#         z = self.relu(z)\n",
    "#         return z, x1, x2\n",
    "    # model = CNN(normal, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc295ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (list(depth.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cadedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(depth.children()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88c157",
   "metadata": {},
   "source": [
    "# cross-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d1bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, normal, depth):\n",
    "        super(CNN, self).__init__()\n",
    "        super(CNN, self).__init__()\n",
    "        self.model1 = normal\n",
    "        self.model2 = depth\n",
    "        self.fc = fc\n",
    "        self.relu =  nn.ReLU()\n",
    "        self.attn = ScaledDotProductAttention(dim=fc)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(165*self.fc,self.fc)\n",
    "        self.fc2 = nn.Linear(165*self.fc,self.fc)\n",
    "        self.out = nn.Linear(self.fc*2,1)\n",
    "    def forward(self, x_train1, x_train2):\n",
    "        x1,context1,key1,query1,value1 = self.model1(x_train1)\n",
    "        x2,context2,key2,query2,value2 = self.model2(x_train2)        \n",
    "        context12, attn12 = self.attn(query1, key2, value2)\n",
    "        context12 = self.flat(context12)\n",
    "        context12 = self.fc1(context12)\n",
    "        context12 = self.relu(context12)\n",
    "        context21, attn21 = self.attn(query2, key1, value1)\n",
    "        context21 = self.flat(context21)\n",
    "        context21 = self.fc2(context21)\n",
    "        context21 = self.relu(context21)\n",
    "        x = torch.cat([context12, context21],dim=1)  \n",
    "        x = self.out(x)\n",
    "        x = self.relu(x)\n",
    "        return x, context12, context12\n",
    "\n",
    "crossattn = CNN(normal, depth)\n",
    "path = 'trained models/attn_cross_6e-05_0.96_attn_3.pt'\n",
    "crossattn.load_state_dict(torch.load(path))\n",
    "crossattn = crossattn.to(device)\n",
    "for param in crossattn.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3284cf",
   "metadata": {},
   "source": [
    "# simple fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d650bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = nn.Sequential(*list(normal.children())[11:12])\n",
    "out_2 = nn.Sequential(*list(depth.children())[8:9])\n",
    "out = torch.cat([out_1[0].weight*0.95, out_2[0].weight*0.05], dim=1)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, normal, depth):  #drop_3, l_1_3, l_2_3, l_3_3\n",
    "        super(CNN, self).__init__()\n",
    "        self.model1 = normal\n",
    "        self.model2 = depth\n",
    "        self.fc = fc\n",
    "        self.relu =  nn.ReLU()\n",
    "        self.out = nn.Linear(2*self.fc,1)\n",
    "        with torch.no_grad():\n",
    "            self.out.weight = nn.Parameter(out)\n",
    "            self.out.bias = nn.Parameter(torch.tensor(np.array([0]), dtype=torch.float))\n",
    "    def forward(self, x_train1, x_train2):\n",
    "        x1,context1,key1,query1,value1 = self.model1(x_train1)\n",
    "        x2,context2,key2,query2,value2 = self.model2(x_train2) \n",
    "        x = torch.cat([context1, context2],dim=1)\n",
    "        x = self.out(x)\n",
    "        x = self.relu(x)\n",
    "        return x, context1, context2\n",
    "model = CNN(normal, depth)\n",
    "\n",
    "simfuse = CNN(normal, depth)\n",
    "path = 'trained models/attn_simple_5e-05_0.96_attn_1.pt'\n",
    "simfuse.load_state_dict(torch.load(path))\n",
    "simfuse = simfuse.to(device)\n",
    "# for param in simfuse.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a6fb3",
   "metadata": {},
   "source": [
    "# attention fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4498d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = list(simfuse.children())[3:4]\n",
    "out2 = list(crossattn.children())[7:8]\n",
    "out = torch.cat([out1[0].weight*0.99, out2[0].weight*0.01], dim=1)\n",
    "bias1 = out1[0].bias + out2[0].bias\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, simfuse, crossattn): \n",
    "        super(CNN, self).__init__()\n",
    "        self.model1 = simfuse\n",
    "        self.model2 = crossattn\n",
    "        self.fc = fc\n",
    "        self.relu =  nn.ReLU()\n",
    "        self.out = nn.Linear(4*self.fc,1)\n",
    "        with torch.no_grad():\n",
    "            self.out.weight = nn.Parameter(out)\n",
    "            self.out.bias = nn.Parameter(bias1)\n",
    "    def forward(self, x_train1, x_train2):\n",
    "        x1,context1,context2 = self.model1(x_train1,x_train2)\n",
    "        x2,context3,context4 = self.model2(x_train1,x_train2) \n",
    "        x = torch.cat([context1, context2, context3, context4],dim=1)\n",
    "        x = self.out(x)\n",
    "        x = self.relu(x)\n",
    "        return x, x1, x2\n",
    "model = CNN(simfuse, crossattn)\n",
    "\n",
    "# multimodal = CNN(normal, depth)\n",
    "# path = 'trained models/attn+_img_7e-05_0.96_fuse-best.pt'\n",
    "# multimodal.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9edda24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out1 = list(simfuse.children())[3:4]\n",
    "# out2 = list(crossattn.children())[7:8]\n",
    "# out = torch.cat([out1[0].weight*0.99, out2[0].weight*0.01], dim=1)\n",
    "# bias1 = out1[0].bias + out2[0].bias\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, normal, depth, crossattn): \n",
    "#         super(CNN, self).__init__()\n",
    "#         self.model1 = normal\n",
    "#         self.model3 = depth\n",
    "#         self.model2 = crossattn\n",
    "#         self.fc = fc\n",
    "#         self.relu =  nn.ReLU()\n",
    "#         self.out = nn.Linear(4*self.fc,1)\n",
    "#         with torch.no_grad():\n",
    "#             self.out.weight = nn.Parameter(out)\n",
    "#             self.out.bias = nn.Parameter(bias1)\n",
    "#     def forward(self, x_train1, x_train2):\n",
    "#         x1, context1, key1, query1, value1 = self.model1(x_train1)\n",
    "#         x2,context3,context4 = self.model2(x_train1,x_train2) \n",
    "#         x3, context2, key2, query2, value2 = self.model3(x_train2)\n",
    "#         x = torch.cat([context1, context2, context3, context4],dim=1)\n",
    "#         x = self.out(x)\n",
    "#         x = self.relu(x)\n",
    "#         return x, x1, x2\n",
    "# model = CNN(normal, depth, crossattn)\n",
    "\n",
    "# # multimodal = CNN(normal, depth)\n",
    "# # path = 'trained models/attn+_img_7e-05_0.96_fuse-best.pt'\n",
    "# # multimodal.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc667a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "# #     for layer in model.state_dict():\n",
    "# #         print(layer)\n",
    "#         #print(torch.ones_like(mask_model.state_dict()[layer].data))\n",
    "# #         mask_model.state_dict()[layer].data.fill_(1)\n",
    "#     model.state_dict()['out.bias'].data.fill_(bias)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f6adc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the model to GP\n",
    "model = model.to(device)\n",
    "\n",
    "b = 0\n",
    "num_warmup_steps = len(train_dataloader) * b\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "import torch.optim as optim\n",
    "from ignite.handlers import param_scheduler\n",
    "\n",
    "lr = 30e-6\n",
    "decay = 0.96\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49659170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "mse  = nn.MSELoss() \n",
    "# metric = nn.RootMeanSquaredError()\n",
    "\n",
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_rmse = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 20 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        x_train1, x_train2, train_cost = batch\n",
    "#         print (x_train.shape)\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds,c1,c2 = model(x_train1, x_train2)\n",
    "#         print (preds[:,0].shape, train_cost.shape)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = mse(preds[:,0], train_cost)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af7341dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_rmse = 0, 0\n",
    "  \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 20 == 0 and not step == 0:\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        x_val1, x_val2, val_cost = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds,c1,c2 = model(x_val1, x_val2)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = mse(preds[:,0],val_cost)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b21f8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dataloader):\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_rmse = 0, 0\n",
    "  \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(test_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 20 == 0 and not step == 0:\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        x_val1, x_val2, val_cost = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds,c1,c2 = model(x_val1, x_val2)\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e8f77d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 1000\n",
      "  Batch    20  of    265.\n",
      "  Batch    40  of    265.\n",
      "  Batch    60  of    265.\n",
      "  Batch    80  of    265.\n",
      "  Batch   100  of    265.\n",
      "  Batch   120  of    265.\n",
      "  Batch   140  of    265.\n",
      "  Batch   160  of    265.\n",
      "  Batch   180  of    265.\n",
      "  Batch   200  of    265.\n",
      "  Batch   220  of    265.\n",
      "  Batch   240  of    265.\n",
      "  Batch   260  of    265.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    20  of     57.\n",
      "  Batch    40  of     57.\n",
      "\n",
      "Training Loss: 0.00013\n",
      "Validation Loss: 0.00164\n",
      "\n",
      " Epoch 2 / 1000\n",
      "  Batch    20  of    265.\n",
      "  Batch    40  of    265.\n",
      "  Batch    60  of    265.\n",
      "  Batch    80  of    265.\n",
      "  Batch   100  of    265.\n",
      "  Batch   120  of    265.\n",
      "  Batch   140  of    265.\n",
      "  Batch   160  of    265.\n",
      "  Batch   180  of    265.\n",
      "  Batch   200  of    265.\n",
      "  Batch   220  of    265.\n",
      "  Batch   240  of    265.\n",
      "  Batch   260  of    265.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    20  of     57.\n",
      "  Batch    40  of     57.\n",
      "\n",
      "Training Loss: 0.00007\n",
      "Validation Loss: 0.00167\n",
      "\n",
      " Epoch 3 / 1000\n",
      "  Batch    20  of    265.\n",
      "  Batch    40  of    265.\n",
      "  Batch    60  of    265.\n",
      "  Batch    80  of    265.\n",
      "  Batch   100  of    265.\n",
      "  Batch   120  of    265.\n",
      "  Batch   140  of    265.\n",
      "  Batch   160  of    265.\n",
      "  Batch   180  of    265.\n",
      "  Batch   200  of    265.\n",
      "  Batch   220  of    265.\n",
      "  Batch   240  of    265.\n",
      "  Batch   260  of    265.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    20  of     57.\n",
      "  Batch    40  of     57.\n",
      "\n",
      "Training Loss: 0.00007\n",
      "Validation Loss: 0.00168\n",
      "\n",
      " Epoch 4 / 1000\n",
      "  Batch    20  of    265.\n",
      "  Batch    40  of    265.\n",
      "  Batch    60  of    265.\n",
      "  Batch    80  of    265.\n",
      "  Batch   100  of    265.\n",
      "  Batch   120  of    265.\n",
      "  Batch   140  of    265.\n",
      "  Batch   160  of    265.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15092\\1351178299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15092\\2286903766.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# get model predictions for the current batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m#         print (preds[:,0].shape, train_cost.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15092\\4051981041.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_train1, x_train2)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15092\\2017213706.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_train1, x_train2)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquery1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquery2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mcontext12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcontext12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15092\\3005487967.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_train)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaolin\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 444\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 1000\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \n",
    "                   'trained models/attn+_fuse_{}_{}_5.pt'.format(lr,decay))\n",
    "        i = 0\n",
    "    else:\n",
    "        i += 1\n",
    "    if i == 3:\n",
    "        break\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Validation Loss: {valid_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "817013e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = cd[cd['set'] == 'test']\n",
    "test_dfx = test_df[test_df['Cd'] > 0.8]\n",
    "test_graph1 = [image1[i] for i in test_dfx['file']]\n",
    "test_graph2 = [image2[i] for i in test_dfx['file']]\n",
    "x_test1 = np.array(test_graph1)/255\n",
    "x_test2 = np.array(test_graph2)/255\n",
    "test_cost = np.array(test_dfx['Cd'])\n",
    "\n",
    "x_test1 = torch.tensor(x_test1,dtype=torch.float)\n",
    "x_test1 = torch.transpose(x_test1, 1, 3)\n",
    "x_test2 = torch.tensor(x_test2,dtype=torch.float)\n",
    "x_test2 = torch.transpose(x_test2, 1, 3)\n",
    "test_cost = torch.tensor(test_cost,dtype=torch.float)\n",
    "\n",
    "test_data = TensorDataset(x_test1, x_test2, test_cost)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e1e5275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbyli\\anaconda3\\envs\\kaolin\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\sbyli\\anaconda3\\envs\\kaolin\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# ##Make Predictions\n",
    "# #load weights of best model\n",
    "path = 'trained models/attn+_fuse_{}_{}_5.pt'.format(lr,decay)\n",
    "# # # path = 'trained models/side_resnext_200_8e-05_128_0.5.pt'\n",
    "# path = 'trained models/attn+_img_7e-05_0.96_fuse-best.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "# get predictions for test data\n",
    "test_result = test(test_dataloader)[:,0]\n",
    "\n",
    "difference_array = np.subtract(test_result, test_cost)\n",
    "squared_array = np.square(difference_array)\n",
    "mse = squared_array.mean().numpy()\n",
    "\n",
    "correlation_matrix = np.corrcoef(test_cost, test_result)\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "\n",
    "idx = 0\n",
    "var = 'integrated'\n",
    "output = pd.DataFrame()\n",
    "# output.loc[idx,'warm up'] = a\n",
    "output.loc[idx,'var'] = var\n",
    "# output.loc[idx,'lr'] = lr\n",
    "output.loc[idx,'mse'] = mse\n",
    "output.loc[idx,'r^2'] = r_squared\n",
    "output.loc[idx,'fc'] = fc\n",
    "output.loc[idx,'lr'] = lr\n",
    "output.loc[idx,'decay'] = decay\n",
    "output.loc[idx,'tolerance'] = 20\n",
    "output.loc[idx,'diff'] = abs(difference_array).mean().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03fdd8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>mse</th>\n",
       "      <th>r^2</th>\n",
       "      <th>fc</th>\n",
       "      <th>lr</th>\n",
       "      <th>decay</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>integrated</td>\n",
       "      <td>0.047334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.96</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.217565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          var       mse  r^2     fc       lr  decay  tolerance      diff\n",
       "0  integrated  0.047334  NaN  128.0  0.00003   0.96       20.0  0.217565"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408d550f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot = pd.DataFrame()\n",
    "plot['Cd'] = test_cost\n",
    "plot['Predicted'] = test_result\n",
    "plot = plot.sort_values(by=['Cd'], ascending = True, na_position='first').reset_index(drop = True)\n",
    "    \n",
    "correlation_matrix = np.corrcoef(plot['Cd'], plot['Predicted'])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "figure(figsize=(4, 3), dpi=400)\n",
    "plt.scatter(plot['Cd'], plot['Predicted'], s = 5)\n",
    "\n",
    "x = [0,1]\n",
    "y = [0,1]\n",
    "plt.plot(x,y, color=\"black\")\n",
    "\n",
    "plt.xlim([0,1])\n",
    " plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel('Ground Truth')\n",
    "plt.ylabel('Predicted')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('attn+_fuset.png'.format(lr,decay),dpi=400)\n",
    "print (var, r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf3c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaolin",
   "language": "python",
   "name": "kaolin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
